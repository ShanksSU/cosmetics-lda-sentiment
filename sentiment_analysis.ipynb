{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07785fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/MediaTek-Research/Llama-Breeze2-8B-Instruct\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import GenerationConfig\n",
    "from mtkresearch.llm.prompt import MRPromptV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0be2ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'MediaTek-Research/Llama-Breeze2-8B-Instruct-v0_1'\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True,\n",
    "    device_map='auto',\n",
    "    img_context_token_id=128212\n",
    ").eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True, use_fast=False)\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "  max_new_tokens=2048,\n",
    "  do_sample=True,\n",
    "  temperature=0.01,\n",
    "  top_p=0.01,\n",
    "  repetition_penalty=1.1,\n",
    "  eos_token_id=128009\n",
    ")\n",
    "\n",
    "prompt_engine = MRPromptV3()\n",
    "\n",
    "sys_prompt = 'You are a helpful AI assistant built by MediaTek Research. The user you are helping speaks Traditional Chinese and comes from Taiwan.'\n",
    "\n",
    "def _inference(tokenizer, model, generation_config, prompt, pixel_values=None):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    if pixel_values is None:\n",
    "        output_tensors = model.generate(**inputs, generation_config=generation_config)\n",
    "    else:\n",
    "        output_tensors = model.generate(**inputs, generation_config=generation_config, pixel_values=pixel_values.to(model.device, dtype=model.dtype))\n",
    "    output_str = tokenizer.decode(output_tensors[0])\n",
    "    return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aed0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_sentiment_llm(text):\n",
    "    system_prompt = \"\"\"\n",
    "        # Role\n",
    "        你是一位精通中文語意學與心理學的情感分析專家。你的任務是分析使用者提供的評論文本，並根據下方的「情緒類別學術定義」進行分類。\n",
    "\n",
    "        # Objective\n",
    "        1. 閱讀輸入的中文評論。\n",
    "        2. 分析文本中的顯性情緒詞（Explicit Sentiment）與隱性情緒（Implicit Sentiment，如諷刺、語氣助詞）。\n",
    "        3. 判斷該評論主要包含的一種或多種情緒。\n",
    "        4. 嚴格按照定義輸出結果，不允許模糊地帶。\n",
    "\n",
    "        # 情緒類別與學術定義\n",
    "        請依據以下心理學與語言學定義進行判斷：\n",
    "\n",
    "        1. **滿意**\n",
    "        - **定義**：當個體評估當前情境與其目標一致，或需求得到滿足時產生的正向情緒。\n",
    "        - **特徵**：包含滿意、興奮、愉悅。在評論中通常表現為對產品/服務的讚賞、推薦意願或感謝。\n",
    "\n",
    "        2. **憤怒/不滿**\n",
    "        - **定義**：當個體感知到目標受阻、受到不公待遇或期待落空時產生的激越情緒。\n",
    "        - **特徵**：包含生氣、敵意、挫折感。在評論中常表現為指責、強烈的負面語氣助詞（如「爛透了」、「氣死」）、或攻擊性語言。\n",
    "\n",
    "        3. **(悲傷/失望**\n",
    "        - **定義**：當個體經歷不可挽回的損失（Loss）或無助感（Helplessness）時產生的低落情緒。\n",
    "        - **特徵**：包含失落、沮喪、遺憾。在評論中表現為對結果的無力感、後悔購買、或委婉的抱怨（如「可惜了...」、「原本以為...」）。\n",
    "\n",
    "        4. **恐懼/焦慮**\n",
    "        - **定義**：當個體感知到潛在威脅、不確定性或無法掌控的情況時產生的防禦性情緒。\n",
    "        - **特徵**：包含擔心、緊張、恐慌。在評論中表現為對產品安全性的疑慮、對售後服務的不確定感、或擔憂。\n",
    "\n",
    "        5. **厭惡/反感**\n",
    "        - **定義**：當個體接觸到被認為是有害、不潔、或違反社會規範的事物時產生的排斥反應。\n",
    "        - **特徵**：包含噁心、鄙視、迴避。在評論中表現為對衛生狀況的批評、對服務態度的極度不屑、或生理上的不適感描述。\n",
    "\n",
    "        6. **驚訝**\n",
    "        - **定義**：當個體遭遇非預期（Unexpected）的事件時產生的短暫情緒狀態（可為正向或負向）。\n",
    "        - **特徵**：包含震驚、錯愕。在評論中表現為「沒想到」、「竟然」、「出乎意料」。\n",
    "        *注意：若驚訝後緊接著強烈的喜悅或憤怒，請同時標註。*\n",
    "\n",
    "        7. **中性**\n",
    "        - **定義**：缺乏明顯的情緒色彩，主要為客觀陳述事實或詢問資訊。\n",
    "        - **特徵**：不帶個人主觀評價的描述。\n",
    "\n",
    "        # Rules\n",
    "        1. 若文本包含諷刺（Sarcasm），請依據其「真實意圖」而非字面意義進行分類（通常歸類為 Disgust 或 Anger）。\n",
    "        2. 若文本包含多種情緒（Mixed Emotions），請列出所有主要情緒。\n",
    "        3. 針對中文特有的語氣助詞（如：喔、吧、耶、蛤）需納入情緒強度的判斷依據。\n",
    "\n",
    "        # Output Format\n",
    "        請以 JSON 格式輸出，重點在於捕捉所有顯著的情緒：\n",
    "\n",
    "        {\n",
    "        \"簡短分析\": \"簡短分析文本中的關鍵詞、語氣轉折與針對的對象...\",\n",
    "        \"情緒\": [\n",
    "            {\n",
    "            \"情緒類別\": \"情緒類別 (使用中文)\",\n",
    "            \"情緒強度\": 1-5 (強度，5為最強烈),\n",
    "            \"該情緒針對的對象\": \"該情緒針對的對象 (例如: 服務, 產品, 物流)\"\n",
    "            }\n",
    "        ]\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"評論內容：{text}\"\n",
    "    conversations = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    prompt = prompt_engine.get_prompt(conversations)\n",
    "    output_str = _inference(tokenizer, model, generation_config, prompt)\n",
    "    result = prompt_engine.parse_generated_str(output_str)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c288fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試\n",
    "test_text_list = [\n",
    "    \"網路上有一家500元的吃到飽，大家的評論都很不錯，有各式各樣的菜色，但我實際去了一趟，發現全是便宜的澱粉類，肉片薄得像紙一樣，補菜還慢得要死。\",\n",
    "    \"網路上有一家500元的吃到飽，大家的評論都很不錯，有各式各樣的菜色，今天去試了確實CP值很高，雖然海鮮不算頂級，但以500元這個價位來說，該有的都有，跟評論描述的差不多，沒讓人失望，是個粗飽的好選擇。\",\n",
    "    \"網路上有一家500元的吃到飽，大家的評論都很不錯，有各式各樣的菜色，結果現場竟然有現切和牛，龍蝦，帝王蟹連甜點都是哈根達斯！\",\n",
    "    \"網路上有一家500元的吃到飽，大家的評論都很不錯，有各式各樣的菜色，但是我只看得到炒飯和薯條，而且蒼蠅還幫忙加菜，這種『五星級』體驗真是讓我大開眼界，謝謝大家推薦喔。\"\n",
    "]\n",
    "\n",
    "for text in test_text_list:\n",
    "    result = analyze_sentiment_llm(text)\n",
    "    print(f\"輸入評論: {text}\\n解析後的結果: {result}\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_222",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
